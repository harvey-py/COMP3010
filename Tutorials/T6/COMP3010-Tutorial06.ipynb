{"cells":[{"cell_type":"markdown","metadata":{"id":"fWNvAif9LqB4"},"source":["# **COMP3010 - Machine Learning**\n","\n","The tutorial contains two parts: (theoretical) discussion and (practical) coding. The discussion part consists of important concepts, advanced topics, or open-ended questions, for which we want an in-depth discussion. The coding part contains programming exercises for you to gain hands on experience.\n","\n","## **Tutorial 06**\n","Learning outcomes:\n","\n","*   Training and evaluating MLP for MNIST\n","*   Realising Data visualization with t-SNE\n","*   Deepen understanding of NN with Playground\n"]},{"cell_type":"markdown","metadata":{"id":"i3BdVmSk1QFu"},"source":["## **Discussion**\n","\n","\n","1.   Explain the ``Universal Approximation Theory\" of NNs. If NN with one hidden layer can fit anything, why do we need deep NN?\n","2.   Where does the term \"deep learning\" come from? What is the difference with \"shallow learning\"?\n","3.   You are training a NN and observed that the training loss becomes NaN after several iterations. What might be the causes and how do you address them. \n","4.   Explain the concept of _batch_size_, _iteration_, and _epoch_ in training NN. How does batch size affect the training of NNs?\n","5.   Discuss regularization techniques for addressing overfitting of NN."]},{"cell_type":"markdown","metadata":{"id":"5oGmB1yK-qIS"},"source":["## **Coding**\n"]},{"cell_type":"markdown","metadata":{"id":"cSdI2ILLknQB"},"source":["In this part, you will\n","\n","*   implement a MLP for MNIST handawritten digits 0-9 recognition.\n","*   implement a data visualization technique named [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n","*   have fun with [NNPlaygroud](https://playground.tensorflow.org/).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dl5c4w3iVrrc"},"source":["## Outline\n","- [ 1 - MLP for MNIST ](#1)\n","  - [ 1.1 Load data](#1.1)\n","  - [ 1.2 - Visualize a batch of data](#1.2)\n","  - [ 1.3 - Define network architecture](#1.3)\n","    - [Exercise 01](#ex01)\n","  - [ 1.4 - Specify loss function and optimizer](#1.4)\n","  - [ 1.5 - Model Training](#1.5)\n","  - [ 1.6 - Model Evaluation](#1.6)\n","- [ 2 - T-SNE visualization](#2)\n","  - [ 2.1 Load data](#2.1)\n","  - [ 2.2 - Visualising the raw data](#2.2)\n","  - [ 2.3 - Visualising leaned features](#2.3)\n","- [ 3 - NN Playground](#3)\n","  - [Exercise 02](#ex02)\n","  - [Exercise 03](#ex03)\n","  - [Exercise 04](#ex04)\n"]},{"cell_type":"markdown","metadata":{"id":"ZEVAQ8GNzPzm"},"source":["<a name=\"1\"></a>\n","## 1 - MLP for MNIST digits recognition\n","---\n","In this sectgion, we will train an MLP to classify images from the [MNIST database](http://yann.lecun.com/exdb/mnist/) hand-written digit database.\n","\n","The process will be broken down into the following steps:\n","1. Load and visualize the data\n","2. Define a neural network\n","3. Train the model\n","4. Evaluate the performance of our trained model on a test dataset!\n","\n","Before we begin,  let's import necessary libraries for working with data and PyTorch.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":307,"status":"ok","timestamp":1705135779305,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"aYZJbuZkL4SL"},"outputs":[],"source":["# import libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{"id":"jXOHx1e2iHGM"},"source":["<a name=\"1.1\"></a>\n","### 1.1 Load data\n","\n","We will download the full MNIST data from torchvision. Downloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time.\n","\n","This cell will create DataLoaders for each of our [datasets]((http://pytorch.org/docs/stable/torchvision/datasets.html))."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":304,"status":"ok","timestamp":1705138181927,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"Hgaq3FuU2bV9"},"outputs":[],"source":["from torchvision import datasets\n","import torchvision.transforms as transforms\n","\n","# how many examples per batch to load\n","batch_size = 16\n","\n","# convert data to torch.FloatTensor\n","transform = transforms.ToTensor()\n","\n","# choose the training and test datasets\n","train_data = datasets.MNIST(root='DATA', train=True, download=True, transform=transform)\n","test_data = datasets.MNIST(root='DATA', train=False, download=True, transform=transform)\n","\n","# prepare data loaders\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"Hbv6a-ag3wFq"},"source":["Note that the full dataset is too big and thus we load data batch by batch, where in each batch we load 16 images. The pytorch dataloader module will handle many cubersome issues, and thus very useful when dealing with large datasets."]},{"cell_type":"markdown","metadata":{"id":"yxydbU7a4XWz"},"source":["<a name=\"1.2\"></a>\n","### 1.2 - Visualize a batch of data\n","\n","The first step in a classification task is to take a look at the data, make sure it is loaded in correctly, then make any initial observations about patterns in that data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":1693,"status":"ok","timestamp":1705135789220,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"Lr6u95CY4i0C","outputId":"6f10f283-6dbd-4fed-d608-3329684502e5"},"outputs":[],"source":["# obtain one batch of training images\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","images = images.numpy()\n","\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(20, 4))\n","for idx in np.arange(batch_size):\n","    ax = fig.add_subplot(2, batch_size//2, idx+1, xticks=[], yticks=[])\n","    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n","    # print out the correct label for each image\n","    # .item() gets the value contained in a Tensor\n","    ax.set_title(str(labels[idx].item()))"]},{"cell_type":"markdown","metadata":{"id":"e_oSfLEh5X8x"},"source":["Check the image dimensions:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705133860026,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"qvE-0xhA5bap","outputId":"74f771e0-9410-4fc8-e501-d85d71344c17"},"outputs":[],"source":["print(images.shape)"]},{"cell_type":"markdown","metadata":{"id":"MFOTDUlr5jsR"},"source":["Pytorch use ``BCHW`` **(batch, channel, height, width)** convention to store image tensors. The above shape tells us that the ``images`` tensor contains a batch of 16 grayscale images of resolution $28\\times28$, i.e., 784 pixels per image."]},{"cell_type":"markdown","metadata":{"id":"P8acKKFO5ILg"},"source":["<a name=\"1.3\"></a>\n","### 1.3 - Define network architecture\n","\n","The architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. These information decides the input and output layers of the neural network. We as users need to define the hidden layers of our NN, including number of layers and neurons as hyperparameters.\n"]},{"cell_type":"markdown","metadata":{"id":"bGBRDFbXqBwz"},"source":["<a name=\"ex01\"></a>\n","### Exercise 01\n","\n","Let's define a MLP with structure s=[784, 256, 64, 10], that is, two hidden layers of size 256 and 64 respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NejP2jLu7wjP"},"outputs":[],"source":["import torch.nn as nn\n","\n","## Define the NN architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        ### START CODE HERE ###\n","\n","        ### END CODE HERE ###\n","\n","    def forward(self, x):\n","        # flatten image input\n","        x = x.view(-1, 28 * 28)\n","\n","        ### START CODE HERE ###\n","\n","        ### END CODE HERE ###\n","        return x\n","\n","# initialize the NN\n","model = Net()\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"iwaPAiYU89y4"},"source":["<a name=\"1.4\"></a>\n","###  1.4 - Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)\n","\n","It's recommended that you use cross-entropy loss for classification. If you look at the documentation (linked above), you can see that PyTorch's cross entropy function applies a softmax funtion to the output layer *and* then calculates the log loss."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1705138016529,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"Nv9G68mZ8BQb"},"outputs":[],"source":["## Specify loss and optimization functions\n","\n","# specify loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# specify optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"J6UX3YBM9Twi"},"source":["<a name=\"1.5\"></a>\n","###  1.5 - Model Training\n","\n","The steps for training/learning from a batch of data are described in the comments below:\n","1. Clear the gradients of all optimized variables\n","2. Forward pass: compute predicted outputs by passing inputs to the model\n","3. Calculate the loss\n","4. Backward pass: compute gradient of the loss with respect to model parameters\n","5. Perform a single optimization step (parameter update)\n","6. Update average training loss\n","\n","The following loop trains for 30 epochs; feel free to change this number. For now, we suggest somewhere between 20-50 epochs. As you train, take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data. Note that the training process is slow as we are iterating through 60,000 images with a batch size of 16 in each epoch. You can speed up this process by switching from CPU to GPU for this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133276,"status":"ok","timestamp":1705138159073,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"_q8oiekZ9d7c","outputId":"bd5df513-05ed-44ca-854c-aef01c9f891e"},"outputs":[],"source":["# number of epochs to train the model\n","n_epochs = 10  # 10 for fast demo, suggest training between 20-50 epochs\n","\n","model.train() # prep model for training\n","\n","for epoch in range(n_epochs):\n","    # monitor training loss\n","    train_loss = 0.0\n","\n","    ###################\n","    # train the model #\n","    ###################\n","    for data, target in train_loader:\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update running training loss\n","        train_loss += loss.item()*data.size(0)\n","\n","    # print training statistics\n","    # calculate average loss over an epoch\n","    train_loss = train_loss/len(train_loader.dataset)\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n","        epoch+1,\n","        train_loss\n","        ))"]},{"cell_type":"markdown","metadata":{"id":"1ojZAmt09yWN"},"source":["<a name=\"1.6\"></a>\n","###  1.6 - Model Evaluation\n","\n","Finally, we test our best model on previously unseen **test data** and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy.\n","\n","#### `model.eval()`\n","\n","`model.eval(`) will set all the layers in your model to evaluation mode, which might be different with train mode for some layers, such as ``dropout``."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2294,"status":"ok","timestamp":1705138197399,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"Fbux_qkg-PbT","outputId":"e5554f0d-6e0e-413b-f9d0-ed74bb6b1636"},"outputs":[],"source":["# initialize lists to monitor test loss and accuracy\n","test_loss = 0.0\n","class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","model.eval() # prep model for *evaluation*\n","with torch.no_grad():  # turn off gradient to save memory\n","  for data, target in test_loader:\n","      # forward pass: compute predicted outputs by passing inputs to the model\n","      output = model(data)\n","      # calculate the loss\n","      loss = criterion(output, target)\n","      # update test loss\n","      test_loss += loss.item()*data.size(0)\n","      # convert output probabilities to predicted class\n","      _, pred = torch.max(output, 1)\n","      # compare predictions to true label\n","      correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n","      # calculate test accuracy for each object class\n","      for i in range(batch_size):\n","          label = target.data[i]\n","          class_correct[label] += correct[i].item()\n","          class_total[label] += 1\n","\n","# calculate and print avg test loss\n","test_loss = test_loss/len(test_loader.dataset)\n","print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","for i in range(10):\n","    if class_total[i] > 0:\n","        print('Test Accuracy of digit %5s: %2d%% (%2d/%2d)' % (\n","            str(i), 100 * class_correct[i] / class_total[i],\n","            np.sum(class_correct[i]), np.sum(class_total[i])))\n","    else:\n","        print('Test Accuracy of digit %5s: N/A (no training examples)' % (classes[i]))\n","\n","print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","    100. * np.sum(class_correct) / np.sum(class_total),\n","    np.sum(class_correct), np.sum(class_total)))"]},{"cell_type":"markdown","metadata":{"id":"_HZXkMjr-oNy"},"source":["### Visualize Sample Test Results\n","\n","\n","This cell displays test images and their labels in this format: `predicted (ground-truth)`. The text will be green for accurately classified examples and red for incorrect predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294},"executionInfo":{"elapsed":1515,"status":"ok","timestamp":1705138205205,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"M3hyY06Y-tvp","outputId":"733e207d-0431-46fd-f953-f937e32b514f"},"outputs":[],"source":["# obtain one batch of test images\n","dataiter = iter(test_loader)\n","images, labels = next(dataiter)\n","\n","# get sample outputs\n","output = model(images)\n","# convert output probabilities to predicted class\n","_, preds = torch.max(output, 1)\n","# prep images for display\n","images = images.cpu().numpy()\n","\n","# plot the images in the batch, along with predicted and true labels\n","fig = plt.figure(figsize=(25, 4))\n","for idx in np.arange(batch_size):\n","    ax = fig.add_subplot(2, batch_size//2, idx+1, xticks=[], yticks=[])\n","    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n","    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n","                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"]},{"cell_type":"markdown","metadata":{"id":"OcmB89el-2w4"},"source":["<a name=\"1.7\"></a>\n","###  1.7 - (Optional) Improve model performance by trying different hyperparameters\n","\n","You can try to improve the model performance by using a different network architecture and longer training."]},{"cell_type":"markdown","metadata":{"id":"vFyv31jw4xYD"},"source":["<a name=\"2\"></a>\n","## 2 - T-SNE visualization\n","---\n","\n","[T-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) is a powerful dimensionality reduction technique that can be used for data visualisation.\n","\n","The idea is that we as human cannot make sense of data with dimensionality higher than 3. Therefore, the goal of t-SNE is to reduce high-dimensional data to low-dimension (ideally 2) so that we can visualize and understand the data.\n","\n","Obviously, the dimensionality reduction process needs to preserve the (manifold) structure of the data, in a way that close examples in the high-dimensional space are still close in the low-dimensional space."]},{"cell_type":"markdown","metadata":{"id":"sIoBredUfSbc"},"source":["<a name=\"2.1\"></a>\n","#### 2.1 Load data\n","\n","We will use 3000 images from the test set of MNIST for this exercise."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":688,"status":"ok","timestamp":1705138211703,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"Rg41exQflqSU","outputId":"d79e37cb-0eb2-4d96-8c01-a4ed4acdcbc5"},"outputs":[],"source":["# how many samples per batch to load\n","batch_size = 3000\n","\n","# transforms to be applied when loading data\n","transform = transforms.ToTensor()\n","\n","# doload test data if not yet\n","test_data = datasets.MNIST(root='DATA', train=False, download=True, transform=transform)\n","\n","# prepare data loaders\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n","\n","# load data\n","dataIter = iter(test_loader)\n","X, label = next(dataIter)\n","\n","# Convert to numpy and flatten images\n","X_np = X.numpy().reshape(3000, -1)\n","print(\"The current data shape is: \", X_np.shape)"]},{"cell_type":"markdown","metadata":{"id":"fMCD66iX5A6S"},"source":["<a name=\"2.2\"></a>\n","#### 2.2 Visualizing the raw data\n","\n","In the code below, we will use tsnet to reduce the data X of shape (3000, 784) to X_embeded of shape (3000, 2) and then plot X_embeded with a scatter plot, color coded by its class label."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":566},"executionInfo":{"elapsed":10822,"status":"ok","timestamp":1705137031181,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"_5XLopJ15Dgq","outputId":"098f78fe-7644-4c60-8fa1-67678beb6c50"},"outputs":[],"source":["from sklearn.manifold import TSNE\n","import seaborn as sns; sns.set_theme()\n","\n","tsne = TSNE(n_components=2,        # number of dimension after embeding\n","            perplexity=30,         # size of nearest neighbour (to be tuned)\n","            learning_rate='auto',\n","            init='pca',\n","            n_iter=300)\n","\n","X_embeded = tsne.fit_transform(X_np)\n","\n","# Create the figure\n","fig = plt.figure(figsize=(8,6))\n","ax = fig.add_subplot(1, 1, 1, title='TSNE of MNIST TEST SET' )\n","\n","# Create the scatter\n","sns.scatterplot(x=X_embeded[:, 0], y=X_embeded[:, 1], hue=label, palette=\"deep\")"]},{"cell_type":"markdown","metadata":{"id":"wLF19kSOFmcV"},"source":["As seen, some digits are well separated from the other, such as `0', '1', '2', while some digits are mixed with each other, such as '4' and '9'. These observation makes sense as handwritten 4 and 9 can be quite similar.\n"]},{"cell_type":"markdown","metadata":{"id":"kyWWcdkkGdZP"},"source":["<a name=\"2.3\"></a>\n","#### 2.3 Visualizing the learned features\n","\n","We mentioned in the lecture that the neural network learns latent representation (embedding) by its hidden layers. Let's visualise these learned representation and see if it's better than the raw representation.\n","\n","We will use the feature after the 2nd hidden layers ``fc2`` (which has dimensionality of 64). Since our NN model has been defined and trained. To extract the intermediate result after fc2, we need to use ``hook`` in pytorch."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1705138615119,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"6zL5tbBzGcwS","outputId":"039daee7-fa64-481e-b487-b08e24e7d92d"},"outputs":[],"source":["extracted_features = []\n","\n","def hook_function(module, input, output):\n","    extracted_features.append(output.clone().detach())\n","\n","hook = model.fc2.register_forward_hook(hook_function)\n","model_output = model(X)\n","X_fc2 = extracted_features[0]  # The features are stored in a list\n","print(\"The data after fc2 has the shape: \", X_fc2.shape)"]},{"cell_type":"markdown","metadata":{"id":"mRHkcKABLoxm"},"source":["We will then visualise this 64 dimensional data using t-SNE again."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":566},"executionInfo":{"elapsed":12897,"status":"ok","timestamp":1705138688870,"user":{"displayName":"QILIN LI","userId":"01132023268323719979"},"user_tz":-480},"id":"E3StEBWyIv_m","outputId":"213bd416-86d3-48ea-cf80-8b54d5347d6e"},"outputs":[],"source":["tsne = TSNE(n_components=2,        # number of dimension after embeding\n","            perplexity=30,         # size of nearest neighbour (to be tuned)\n","            learning_rate='auto',\n","            init='pca',\n","            n_iter=300)\n","\n","X_embeded = tsne.fit_transform(X_fc2)\n","\n","# Create the figure\n","fig = plt.figure(figsize=(8,6))\n","ax = fig.add_subplot(1, 1, 1, title='TSNE of MNIST TEST SET after fc2')\n","\n","# Create the scatter\n","sns.scatterplot(x=X_embeded[:, 0], y=X_embeded[:, 1], hue=label, palette=\"deep\")"]},{"cell_type":"markdown","metadata":{"id":"9gx_rGU7L3PV"},"source":["As shown, the data are much better separated. In particular, the dights '4' and '9' are well separated. Applying a classifer on this representation will obtain better performance than on the raw representation. This is the power of feature learning, which is the essence of deep learning. We will see more examples in later lectures and tutorials.\n","\n","Note that the t-sne embedding can be adjusted or tuned by its hyperparameters as well, in particular, the ``perplexity=30``. You can try use t-sne with other features, e.g., after fc3."]},{"cell_type":"markdown","metadata":{"id":"_xIOTHXygmuX"},"source":["<a name=\"3\"></a>\n","## 3 NN Playground\n"]},{"cell_type":"markdown","metadata":{"id":"en9DziUJhUYv"},"source":["The [neural network playground]((https://playground.tensorflow.org/)) provides a webbroswer based tool for playing with neural networks. In particular, we could visualize how NN is trained and what the **deicion boundary** looks like.\n","\n","You can play it yourself or you can try to go through the following exercises.\n","               "]},{"cell_type":"markdown","metadata":{"id":"FVqeqnxyruOb"},"source":["<a name=\"ex02\"></a>\n","### Exercise 02: XOR data (The 2nd one)\n","\n","**Task 1**: Start with the model of 1 hidden layer 1 neuron with linear activation. The NN model combines our two input features into a single neuron. Will this model learn any nonlinearities? Run it to confirm your guess.\n","\n","**Task 2**: Try increasing the number of neurons in the hidden layer from 1 to 2, and also try changing from a Linear activation to a nonlinear activation like ReLU. Can you create a model that can learn nonlinearities? Can it model the data effectively?\n","\n","**Task 3**: Try increasing the number of neurons in the hidden layer from 2 to 3, using a nonlinear activation like ReLU. Can it model the data effectively? How does model quality vary from run to run?\n","\n","**Task 4**: Continue experimenting by adding or removing hidden layers and neurons per layer. Also feel free to change learning rates, regularization, and other learning settings. What is the smallest number of neurons and layers you can use that gives test loss of 0.177 or lower?\n","\n","Does increasing the model size improve the fit, or how quickly it converges? Does this change how often it converges to a good model? For example, try the following architecture:\n","\n","- First hidden layer with 3 neurons.\n","- Second hidden layer with 3 neurons.\n","- Third hidden layer with 2 neurons."]},{"cell_type":"markdown","metadata":{"id":"Sk7iiOoXr25L"},"source":["<a name=\"ex03\"></a>\n","### Exercise 03: XOR data\n","\n","This exercise uses the XOR data again, but looks at the repeatability of training Neural Nets and the importance of initialization. Use a NN with 1 hidden layer 3 hidden neurons with ReLU activation.\n","\n","**Task 1**: Run the model as given four or five times. Before each trial, hit the Reset the network button to get a new random initialization. (The Reset the network button is the circular reset arrow just to the left of the Play button.) Let each trial run for at least 500 steps to ensure convergence. What shape does each model output converge to? What does this say about the role of initialization in non-convex optimization?\n","\n","**Task 2**: Try making the model slightly more complex by adding a layer and a couple of extra nodes. Repeat the trials from Task 1. Does this add any additional stability to the results?"]},{"cell_type":"markdown","metadata":{"id":"UfLdDDlrsAvD"},"source":["<a name=\"ex04\"></a>\n","### Exercise 04: Neural Net Spiral (the last one)\n","\n","This data set is a noisy spiral. Obviously, a linear model will fail here, but even manually defined feature crosses may be hard to construct.\n","\n","**Task 1**: Train the best model you can, using just X1 and X2. Feel free to add or remove layers and neurons, change learning settings like learning rate, regularization rate, and batch size. What is the best test loss you can get? How smooth is the model output surface?\n","\n","**Task 2**: Even with Neural Nets, some amount of feature engineering is often needed to achieve best performance. Try adding in additional cross product features or other transformations like sin(X1) and sin(X2). Do you get a better model? Is the model output surface any smoother?"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN8PHzUpWTziVMbx01QJnUi","provenance":[{"file_id":"1c5OK5NAJ-F1wK2GjZUCocJlvTxKScE1h","timestamp":1705132435397},{"file_id":"18DVIzNLi1F2GHZl9Aj7PcmvSPCRoWrhH","timestamp":1705109337213},{"file_id":"1pBZPW8W-GeT-LJ6Ruav7N-DkowsS4nFG","timestamp":1705033585893},{"file_id":"1nGPchPxessD8iQ-SOcpBx-MG8xweGsv-","timestamp":1704790509697},{"file_id":"1d5urodzMUrldDaizDkoRggzF11RYCqdS","timestamp":1704777140011}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
