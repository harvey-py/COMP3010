{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWNvAif9LqB4"
   },
   "source": [
    "# **COMP3010 - Machine Learning**\n",
    "\n",
    "The tutorial contains two parts: (theoretical) discussion and (practical) coding. The discussion part consists of important concepts, advanced topics, or open-ended questions, for which we want an in-depth discussion. The coding part contains programming exercises for you to gain hands on experience.\n",
    "\n",
    "## **Tutorial 05**\n",
    "Learning outcomes:\n",
    "\n",
    "*   Implement neural networks using Pytorch\n",
    "*   Implement neural networks using Numpy\n",
    "*   Apply neural networks for handwritten digits recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3BdVmSk1QFu"
   },
   "source": [
    "## **Discussion**\n",
    "\n",
    "1.  Discuss data-preprocessing techniques or steps, in particular for tabular data.\n",
    "\n",
    "2.  How do the different types of layers (input, hidden, output) contribute to a neural network's functionality?\n",
    "\n",
    "3.  Can you discuss the importance of activation functions in neural networks?\n",
    "\n",
    "4.  Explain the output layer and loss of NNs for different learning tasks, regression, binary classification, multi-class classification.\n",
    "\n",
    "5.  Discuss the characteristics of image datasets. What's the difference with tabular dataset? How does MLP deal with image data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oGmB1yK-qIS"
   },
   "source": [
    "## **Coding**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSdI2ILLknQB"
   },
   "source": [
    "In this part, you will implement a simple feedforward neural network, aka Multi-Layer Perceptron (MLP), using Pytorch and Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl5c4w3iVrrc"
   },
   "source": [
    "## Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 - Neural Networks ](#2)\n",
    "  - [ 2.1 - Problem Statement](#2.1)\n",
    "  - [ 2.2 - Dataset](#2.2)\n",
    "    - [ 2.2.1 - View the variables](#2.2.1)\n",
    "    - [2.2.2 Check the dimensions of your variables](#2.2.2)\n",
    "    - [2.2.3 Visualising the data](#2.2.3)\n",
    "  - [ 2.3 - Model representation](#2.3)\n",
    "  - [ 2.4 - Pytorch Model Implementation](#2.4)\n",
    "    - [ Exercise01 ](#ex01)\n",
    "  - [ 2.5 NumPy Model Implementation (Forward Prop in NumPy)](#2.5)\n",
    "    - [ Exercise02](#ex02)\n",
    "- [ 3 - NumPy Broadcasting Tutorial (Optional)](#3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEVAQ8GNzPzm"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages\n",
    "\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment.\n",
    "- [numpy](https://numpy.org/) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a popular library to plot graphs in Python.\n",
    "- [pytorch](https://www.pytorch.org/) is a popular platform for deep learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5399,
     "status": "ok",
     "timestamp": 1705129226252,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "aYZJbuZkL4SL"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXOHx1e2iHGM"
   },
   "source": [
    "Some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1705131687226,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "Hgaq3FuU2bV9"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.load(\"week5X.npy\")\n",
    "    y = np.load(\"week5y.npy\", allow_pickle=True)\n",
    "    X = X[0:1000]\n",
    "    y = y[0:1000]\n",
    "    return X, y\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtCWAYIK27lj"
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Neural Networks\n",
    "\n",
    "So far, you  have implemented logistic regression and SVM which can handle linear classification. This was extended to handle non-linear boundaries using kernel trick. For even more complex scenarios such as image recognition, neural networks are preferred.\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 Problem Statement\n",
    "\n",
    "In this exercise, you will use a neural network to recognize two handwritten digits, zero and one. This is a binary classification task. Automated handwritten digit recognition is widely used today - from recognizing zip codes (postal codes) on mail envelopes to recognizing amounts written on bank checks.\n",
    "\n",
    "This exercise will show you how the methods you have learned can be used for this classification task.\n",
    "\n",
    "<a name=\"2.2\"></a>\n",
    "### 2.2 Dataset\n",
    "\n",
    "You will start by loading the dataset for this task.\n",
    "- The `load_data()` function shown below loads the data into variables `X` and `y`\n",
    "\n",
    "\n",
    "- The data set contains 1000 training examples of handwritten digits $^1$, here limited to zero and one.  \n",
    "\n",
    "    - Each training example is a 20-pixel x 20-pixel grayscale image of the digit.\n",
    "        - Each pixel is represented by a floating-point number indicating the grayscale intensity at that location.\n",
    "        - The 20 by 20 grid of pixels is “unrolled” into a 400-dimensional vector.\n",
    "        - Each training example becomes a single row in our data matrix `X`.\n",
    "        - This gives us a 1000 x 400 matrix `X` where every row is a training example of a handwritten digit image.\n",
    "\n",
    "$$X =\n",
    "\\left(\\begin{array}{cc}\n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (x^{(n)}) ---\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "- The second part of the training set is a 1000 x 1 dimensional vector `y` that contains labels for the training set\n",
    "    - `y = 0` if the image is of the digit `0`, `y = 1` if the image is of the digit `1`.\n",
    "\n",
    "$^1$<sub> This is a subset of the MNIST handwritten digit dataset (http://yann.lecun.com/exdb/mnist/)</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(os.path.join(os.getcwd(),'data/week5X.npy'))\n",
    "y = np.load(os.path.join(os.getcwd(),'data/week5y.npy'))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1705131826516,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "3gOf8REjm54N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 15.2M  100 15.2M    0     0  6831k      0  0:00:02  0:00:02 --:--:-- 24.6M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  5128  100  5128    0     0   6329      0 --:--:-- --:--:-- --:--:--  6329\n"
     ]
    }
   ],
   "source": [
    "!curl -LJO https://github.com/qilinli/COMP3010-Machine-Learning/raw/master/week5X.npy\n",
    "!curl -LJO https://github.com/qilinli/COMP3010-Machine-Learning/raw/master/week5y.npy\n",
    "\n",
    "# load dataset\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFyv31jw4xYD"
   },
   "source": [
    "<a name=\"2.2.1\"></a>\n",
    "#### 2.2.1 View the variables\n",
    "Let's get more familiar with your dataset.  \n",
    "- A good place to start is to print out each variable and see what it contains.\n",
    "\n",
    "The code below prints elements of the variables `X` and `y`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1705129258792,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "Heu9RVs64ynT",
    "outputId": "297db7cf-ef16-4bfb-f08a-7c347d2ea1fe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X is:  0.0\n",
      "The first element of y is:  0\n",
      "The last element of y is:  1\n"
     ]
    }
   ],
   "source": [
    "print ('The first element of X is: ', X[0][0])\n",
    "print ('The first element of y is: ', y[0,0])\n",
    "print ('The last element of y is: ', y[-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIoBredUfSbc"
   },
   "source": [
    "<a name=\"2.2.2\"></a>\n",
    "#### 2.2.2 Check the dimensions of your variables\n",
    "\n",
    "Another way to get familiar with your data is to view its dimensions. Please print the shape of `X` and `y` and see how many training examples you have in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1705129262261,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "Rg41exQflqSU",
    "outputId": "75aed2c5-c557-481f-a280-9c82652ed9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (1000, 400)\n",
      "The shape of y is: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X is: ' + str(X.shape))\n",
    "print ('The shape of y is: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMCD66iX5A6S"
   },
   "source": [
    "<a name=\"2.2.3\"></a>\n",
    "#### 2.2.3 Visualizing the Data\n",
    "\n",
    "You will begin by visualizing a subset of the training set.\n",
    "- In the cell below, the code randomly selects 64 rows from `X`, maps each row back to a 20 pixel by 20 pixel grayscale image and displays the images together.\n",
    "- The label for each image is displayed above the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "executionInfo": {
     "elapsed": 8515,
     "status": "ok",
     "timestamp": 1705129272836,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "_5XLopJ15Dgq",
    "outputId": "5b87c558-4385-46a6-c555-f1695a3c32f1"
   },
   "outputs": [],
   "source": [
    "# You do not need to modify anything in this cell\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "n, d = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1)\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(n)\n",
    "\n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "\n",
    "    # Display the label above the image\n",
    "    ax.set_title(y[random_index,0])\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xIOTHXygmuX"
   },
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3 Model representation\n",
    "\n",
    "The neural network you will use in this assignment is shown in the figure below.\n",
    "- This has three dense layers with sigmoid activations.\n",
    "- Recall that our inputs are pixel values of digit images.\n",
    "- Since the images are of size $20\\times20$, this gives us $400$ inputs  \n",
    "    \n",
    "<img src=\"https://github.com/greyhatguy007/Machine-Learning-Specialization-Coursera/blob/main/C2%20-%20Advanced%20Learning%20Algorithms/week1/C2W1A1/images/C2_W1_Assign1.PNG?raw=true\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en9DziUJhUYv"
   },
   "source": [
    "- The parameters have dimensions that are sized for a neural network with $25$ units in layer 1, $15$ units in layer 2 and $1$ output unit in layer 3.\n",
    "\n",
    "    - Recall that the dimensions of these parameters are determined as follows:\n",
    "        - If network has $s_{in}$ units in a layer and $s_{out}$ units in the next layer, then\n",
    "            - $W$ will be of dimension $s_{in} \\times s_{out}$.\n",
    "            - $b$ will a vector with $s_{out}$ elements\n",
    "  \n",
    "    - Therefore, the shapes of `W`, and `b`,  are\n",
    "        - layer1: The shape of `W1` is (400, 25) and the shape of `b1` is (25,)\n",
    "        - layer2: The shape of `W2` is (25, 15) and the shape of `b2` is: (15,)\n",
    "        - layer3: The shape of `W3` is (15, 1) and the shape of `b3` is: (1,)\n",
    ">**Note:** The bias vector `b` could be represented as a 1-D (n,) or 2-D (n,1) array.\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8ZkohiAhiwi"
   },
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 Pytorch Model Implementation\n",
    "\n",
    "In Pytorch, we normally define neural network modules as a class, inheriting from the base class ``nn.Module``. The class consists of two functions: ``__init__`` and ``forward``. The former is a constructor that initialises the neural network, in particular its layers. The later defines the forward pass, which takes an input tensor ``x`` and returns the output tensor. Note that we don't need to define the backward pass, as it is handled automatically by Pytorch (based on the forward computation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui7j01vppsEK"
   },
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercise 1\n",
    "\n",
    "Below, using [Pytorch](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) with a sigmoid activation to construct the network described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1705129295791,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "Gg2wTUJ1tO99",
    "outputId": "410d864d-af79-41b7-8e65-44720f3d3e7b"
   },
   "outputs": [],
   "source": [
    "class torchNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "torch_nn = torchNN()\n",
    "print(torch_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ISyxdOvwID2"
   },
   "source": [
    "Let's further examine the weights to verify that pytorch produced the same dimensions as we calculated above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1705129326162,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "AQUkSLlquC56",
    "outputId": "4b25a6fa-833d-41e9-e290-edbd53836df6"
   },
   "outputs": [],
   "source": [
    "### Check the index of layers in the print(torch_nn)\n",
    "W1, b1 = torch_nn.layers[0].weight, torch_nn.layers[0].bias\n",
    "W2, b2 = torch_nn.layers[2].weight, torch_nn.layers[2].bias\n",
    "W3, b3 = torch_nn.layers[4].weight, torch_nn.layers[4].bias\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-ljZDzcyFcV"
   },
   "source": [
    "**Expected Output**\n",
    "```\n",
    "W1 shape = torch.Size([25, 400]), b1 shape = torch.Size([25])\n",
    "W2 shape = torch.Size([15, 25]), b2 shape = torch.Size([15])\n",
    "W3 shape = torch.Size([1, 15]), b3 shape = torch.Size([1])\n",
    "```\n",
    "note that pytorch stores weights in the shape __(out_features, in_features)__ and transposes them during the forward pass due to a combination of historical conventions, computational efficiency, and alignment with mathematical notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7_UL6USyrrP"
   },
   "source": [
    "The following code will define a loss function and run gradient descent to fit the weights of the model to the training data. This will be explained in more detail in the following week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2172,
     "status": "ok",
     "timestamp": 1705129331371,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "D2sMpiyfyt9L"
   },
   "outputs": [],
   "source": [
    "## Specify loss and optimization functions\n",
    "\n",
    "# specify loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# specify optimizer\n",
    "# Use Adam with learning rate 0.001 (we will talk about Adam in later lecture)\n",
    "optimizer = torch.optim.Adam(torch_nn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KM-s9tA00-u"
   },
   "source": [
    "---\n",
    "### Train the Network\n",
    "\n",
    "The steps for training/learning from a batch of data are described in the comments below:\n",
    "1. Clear the gradients of all optimized variables\n",
    "2. Forward pass: compute predicted outputs by passing inputs to the model\n",
    "3. Calculate the loss\n",
    "4. Backward pass: compute gradient of the loss with respect to model parameters\n",
    "5. Perform a single optimization step (parameter update)\n",
    "\n",
    "The following loop trains for 300 epochs; feel free to change this number. As you train, take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1705130915531,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "XXGRk5K_8BhV"
   },
   "outputs": [],
   "source": [
    "# Conver numpy data to torch tensor\n",
    "X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "y_torch = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1705130918607,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "GWWD23o-2PGq",
    "outputId": "f28b08d4-96b6-4e31-b8a7-36aab74ba98f"
   },
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 300\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  # clear the gradients of all optimized variables\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # forward pass: compute predicted outputs by passing inputs to the model\n",
    "  output = torch_nn(X_torch)\n",
    "\n",
    "  # calculate the loss\n",
    "  loss = criterion(output, y_torch)\n",
    "\n",
    "  # backward pass: compute gradient of the loss with respect to model parameters\n",
    "  loss.backward()\n",
    "\n",
    "  # perform a single optimization step (parameter update)\n",
    "  optimizer.step()\n",
    "\n",
    "  print(f\"Epoch {epoch}/{n_epochs}: loss {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WkxSc5e8HiV"
   },
   "source": [
    "To run the model on an example with a forward pass to make a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1705130935597,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "qjSREAGa8Pg7",
    "outputId": "4af9f3d4-172b-42ca-c921-b587a3d2e518"
   },
   "outputs": [],
   "source": [
    "prediction = torch_nn(X_torch[0])  # a zero\n",
    "print(f\" predicting a zero: {prediction}\")\n",
    "prediction = torch_nn(X_torch[500])  # a one\n",
    "print(f\" predicting a one:  {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7Ie9Gi99ny7"
   },
   "source": [
    "The output of the model is interpreted as a probability. In the first example above, the input is a zero. The model predicts the probability that the input is a one is nearly zero.\n",
    "In the second example, the input is a one. The model predicts the probability that the input is a one is nearly one.\n",
    "As in the case of logistic regression, the probability is compared to a threshold to make a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1705130942751,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "jv0p3QXo94Yl",
    "outputId": "63980ce4-da46-48b7-8b19-8947bf22f8dc"
   },
   "outputs": [],
   "source": [
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print(f\"prediction after threshold: {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkHH2Zd-97d4"
   },
   "source": [
    "Let's compare the predictions vs the labels for a random sample of 64 digits. This takes a moment to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "executionInfo": {
     "elapsed": 11086,
     "status": "ok",
     "timestamp": 1705130973088,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "V933ArUG994z",
    "outputId": "451e7c50-22e8-4cf7-cf01-80b9a2022b25"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "n, d = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(n)\n",
    "\n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X_torch[random_index].reshape((20,20)).T\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "\n",
    "    # Predict using the Neural Network\n",
    "    prediction = torch_nn(X_torch[random_index])\n",
    "    if prediction >= 0.5:\n",
    "        yhat = 1\n",
    "    else:\n",
    "        yhat = 0\n",
    "\n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{int(y[random_index,0])},{yhat}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, yhat\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd-llUHAiANW"
   },
   "source": [
    "<a name=\"2.5\"></a>\n",
    "### 2.5 NumPy Model Implementation (Forward Prop in NumPy)\n",
    "It is possible to build your own dense layer using NumPy. This can then be utilized to build a multi-layer neural network. The full operation is $\\mathbf{Z}=\\mathbf{XW^T}+\\mathbf{b}$. This will utilize NumPy broadcasting to expand $\\mathbf{b}$ to $n$ rows. If this is unfamiliar, a short tutorial is provided at the end of the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSdFcvxI_zwY"
   },
   "source": [
    "<a name=\"ex02\"></a>\n",
    "### Exercise 2\n",
    "\n",
    "Below, compose a new `my_dense` subroutine that performs the layer calculations for a matrix of examples. This will utilize `np.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSxdqjdRCAnL"
   },
   "outputs": [],
   "source": [
    "def my_dense(X_in, W, b, g):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      X_in (ndarray (n, d)) : Data, n examples, d features each\n",
    "      W    (ndarray (d_out, d_in)) : Weight matrix, d_out times d_in\n",
    "      b    (ndarray (1, d_out)) : bias vector,  d_out units\n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      X_out (ndarray (n, d_out)) : n examples, d_out units\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return X_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdSuh46lA0JV"
   },
   "source": [
    "let's do a simple test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1705129401760,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "sicz6eFvAzfq",
    "outputId": "96fdabf8-77d5-466b-c219-5d28b35406d2"
   },
   "outputs": [],
   "source": [
    "X_tst = 0.1*np.arange(1,9,1).reshape(4,2) # (4 examples, 2 features)\n",
    "W_tst = 0.1*np.arange(1,7,1).reshape(3,2) # (3 output features, 2 input features)\n",
    "b_tst = 0.1*np.arange(1,4,1).reshape(1,3) # (1, 3 features)\n",
    "A_tst = my_dense(X_tst, W_tst, b_tst, sigmoid)\n",
    "print(A_tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCy0RNx4B20x"
   },
   "source": [
    "**Expected Output**\n",
    "```\n",
    "(4,3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUspZoAFoyiS"
   },
   "source": [
    "The following cell builds a three-layer neural network utilizing the `my_dense` subroutine above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1705129739675,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "io1QSMZIo3Th"
   },
   "outputs": [],
   "source": [
    "def numpy_nn(x, W1, b1, W2, b2, W3, b3):\n",
    "    a1 = my_dense(x,  W1, b1, sigmoid)\n",
    "    a2 = my_dense(a1, W2, b2, sigmoid)\n",
    "    a3 = my_dense(a2, W3, b3, sigmoid)\n",
    "    return a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxeikKsJpNVD"
   },
   "source": [
    "We can copy trained weights and biases from Pytorch. (otherwise we need to write cubersome code for backpropagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1705130989653,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "N9Vr1KlOpMuV",
    "outputId": "10a6a7df-ebd9-4fa9-93d1-024820894a96"
   },
   "outputs": [],
   "source": [
    "W1, b1 = torch_nn.layers[0].weight, torch_nn.layers[0].bias\n",
    "W2, b2 = torch_nn.layers[2].weight, torch_nn.layers[2].bias\n",
    "W3, b3 = torch_nn.layers[4].weight, torch_nn.layers[4].bias\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")\n",
    "\n",
    "# Convert pytorch tensors to numpy array\n",
    "W1, b1 = W1.detach().numpy(), b1.detach().numpy()\n",
    "W2, b2 = W2.detach().numpy(), b2.detach().numpy()\n",
    "W3, b3 = W3.detach().numpy(), b3.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1705130993638,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "Wlu6vP6KpjmN",
    "outputId": "d92f3d1c-b9e7-4d6c-9848-e7c3a3607450"
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "prediction = numpy_nn(X[0], W1, b1, W2, b2, W3, b3)\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print( \"yhat = \", yhat, \" label= \", y[0,0])\n",
    "\n",
    "prediction = numpy_nn(X[500], W1, b1, W2, b2, W3, b3)\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print( \"yhat = \", yhat, \" label= \", y[500,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxmBCFpNqQ1R"
   },
   "source": [
    "Run the following cell to see predictions from both the Numpy model and the Pytorch model. This takes a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "executionInfo": {
     "elapsed": 9795,
     "status": "ok",
     "timestamp": 1705131033969,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "heI2958xqRz-",
    "outputId": "6c0c142e-01cc-4ce2-84ce-49a918e70c48"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# You do not need to modify anything in this cell\n",
    "\n",
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(8,8))\n",
    "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "\n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = X[random_index].reshape((20,20)).T\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "\n",
    "    # Predict using the Neural Network implemented in Numpy\n",
    "    np_prediction = numpy_nn(X[random_index], W1, b1, W2, b2, W3, b3)\n",
    "    np_yhat = int(np_prediction >= 0.5)\n",
    "\n",
    "    # Predict using the Neural Network implemented in Tensorflow\n",
    "    pt_prediction = torch_nn(X_torch[random_index])\n",
    "    pt_yhat = int(pt_prediction >= 0.5)\n",
    "\n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{int(y[random_index,0])},{pt_yhat},{np_yhat}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, yhat Pytorch, yhat Numpy\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7AaqlBZq6jU"
   },
   "source": [
    "You can see how one of the misclassified images looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1705131088429,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "NMzke0F9q-n0",
    "outputId": "c18651cb-e33f-480d-f943-66b0e770ad22"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1, 1))\n",
    "np_prediction = numpy_nn(X, W1, b1, W2, b2, W3, b3)\n",
    "np_yhat = (np_prediction > 0.5).astype(int)\n",
    "errors = np.where(y != np_yhat)\n",
    "random_index = errors[0][0]\n",
    "X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "plt.imshow(X_random_reshaped, cmap='gray')\n",
    "plt.title(f\"{y[random_index, 0]}, {np_yhat[random_index, 0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_y5iT9rtu-H2"
   },
   "source": [
    "Congratulations!\n",
    "You have successfully built and utilized a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vp_MIX4JWmB"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 -  NumPy Broadcasting Tutorial (Optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX-Kz2XvnfOw"
   },
   "source": [
    "In the last example,  $\\mathbf{Z}=\\mathbf{XW} + \\mathbf{b}$ utilized NumPy broadcasting to expand the vector $\\mathbf{b}$. If you are not familiar with NumPy Broadcasting, this short tutorial is provided.\n",
    "\n",
    "$\\mathbf{XW}$  is a matrix-matrix operation with dimensions $(m,j_1)(j_1,j_2)$ which results in a matrix with dimension  $(m,j_2)$. To that, we add a vector $\\mathbf{b}$ with dimension $(1,j_2)$.  $\\mathbf{b}$ must be expanded to be a $(m,j_2)$ matrix for this element-wise operation to make sense. This expansion is accomplished for you by NumPy broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LjmNP0OvIaW"
   },
   "source": [
    "Broadcasting applies to element-wise operations.  \n",
    "Its basic operation is to 'stretch' a smaller dimension by replicating elements to match a larger dimension.\n",
    "\n",
    "More [specifically](https://NumPy.org/doc/stable/user/basics.broadcasting.html):\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when\n",
    "- they are equal, or\n",
    "- one of them is 1   \n",
    "\n",
    "If these conditions are not met, a ValueError: operands could not be broadcast together exception is thrown, indicating that the arrays have incompatible shapes. The size of the resulting array is the size that is not 1 along each axis of the inputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4OSsxAFvRZ-"
   },
   "source": [
    "For each of the following examples, try to guess the size of the result before running the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1705131195802,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "2FA3X2uFnexK",
    "outputId": "b6d1426d-f0d2-4531-f771-b1e0396f19cc"
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)  #(3,1)\n",
    "b = 5\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrfeF4-lnxI2"
   },
   "source": [
    "Note that this applies to all element-wise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1705131214201,
     "user": {
      "displayName": "QILIN LI",
      "userId": "01132023268323719979"
     },
     "user_tz": -480
    },
    "id": "zCHPuk_ZvXKx",
    "outputId": "2258ba2a-baa7-486c-b7b6-56d3e620209a"
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)  #(3,1)\n",
    "b = 5\n",
    "print(f\"(a * b).shape: {(a * b).shape}, \\na * b = \\n{a * b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpnckgjMvaPq"
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4]).reshape(-1,1)\n",
    "b = np.array([1,2,3]).reshape(1,-1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM4YL1qkfGp1729VAMoZshr",
   "provenance": [
    {
     "file_id": "18DVIzNLi1F2GHZl9Aj7PcmvSPCRoWrhH",
     "timestamp": 1705109337213
    },
    {
     "file_id": "1pBZPW8W-GeT-LJ6Ruav7N-DkowsS4nFG",
     "timestamp": 1705033585893
    },
    {
     "file_id": "1nGPchPxessD8iQ-SOcpBx-MG8xweGsv-",
     "timestamp": 1704790509697
    },
    {
     "file_id": "1d5urodzMUrldDaizDkoRggzF11RYCqdS",
     "timestamp": 1704777140011
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
