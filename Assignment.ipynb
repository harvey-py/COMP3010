{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/harvey-py/COMP3010/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqRyIkF01Ha9"
   },
   "outputs": [],
   "source": [
    "working_dir = \"~/Documents/GitHub/COMP3010/Assignment/Data/\"\n",
    "\n",
    "train_dir = os.path.join(working_dir, \"train.csv\")\n",
    "test_dir = os.path.join(working_dir, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(train_dir)\n",
    "raw_data.rename(columns = {\"Target Pressure (bar)\": \"tgt_pressure\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_data = pd.read_csv(test_dir)\n",
    "raw_test_data.rename(columns = {\"Target Pressure (bar)\": \"tgt_pressure\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.hist(figsize = (8,8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_num = raw_data.select_dtypes(include=[np.number])\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(len(raw_data_num.columns) / n_cols) + (len(raw_data_num.columns) % n_cols > 0)\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, 20))\n",
    "\n",
    "for i, col_name in enumerate(raw_data_num.columns):\n",
    "    if col_name != \"tgt_pressure\":\n",
    "        ax = axs[i//n_cols, i%n_cols]\n",
    "        ax.scatter(raw_data_num[col_name], raw_data_num[\"tgt_pressure\"])\n",
    "        ax.set_title(f\"{col_name} vs tgt_pressure\")\n",
    "        ax.set_xlabel(col_name)\n",
    "        ax.set_ylabel(\"tgt_pressure\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_num.corr().style.background_gradient(cmap = \"coolwarm\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_num.corr()[[\"tgt_pressure\"]].T.style.background_gradient(cmap = \"coolwarm\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_num[\"Volume\"] = raw_data_num[\"Tank Length (m)\"] * raw_data_num[\"Tank Height (m)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TURN OFF NIGHT READER WHEN VIEWING CORRPLOTS\n",
    "raw_data_num.corr()[[\"tgt_pressure\"]].T.style.background_gradient(cmap = \"coolwarm\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_nans = raw_data[raw_data.isna().any(axis = 1)]\n",
    "print(f\"{len(raw_nans)} points with NaNs out of {len(raw_data)} ({len(raw_nans)/len(raw_data)*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Removing NaNs\n",
    "raw_data1 = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Removing Outliers\n",
    "def remove_outliers_IQR(df, cols, quantile = 0.25, mult = 1.5):\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(quantile)\n",
    "        Q3 = df[col].quantile(1-quantile)\n",
    "        \n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - mult * IQR\n",
    "        upper_bound = Q3 + mult * IQR\n",
    "\n",
    "        n_prior = len(df)\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "        n_after = len(df)\n",
    "        \n",
    "        print(f\"##### {col} #####\\nBounds: {lower_bound:.5f} - {upper_bound:.5f} (IQR: {IQR:.5f})\\nn(removed): {n_prior - n_after}\\n\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data2 = remove_outliers_IQR(raw_data1, [\"Tank Failure Pressure (bar)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding & Incorrect Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1: Encoding Status Column\n",
    "raw_data2[\"Status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data2.loc[raw_data2['Status'].str.contains('sub|cool', case=False), 'Status'] = 'Subcooled'\n",
    "raw_data2.loc[raw_data2['Status'].str.contains('super|heat', case=False), 'Status'] = 'Superheated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data2[\"Status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([raw_data2, pd.get_dummies(raw_data2['Status'], drop_first=True).astype(int)], axis=1)\n",
    "raw_data3 = temp.drop(columns = \"Status\").rename(columns = {\"Superheated\": \"Superheated_status\"})\n",
    "\n",
    "temp = pd.concat([raw_test_data, pd.get_dummies(raw_test_data['Status'], drop_first=True).astype(int)], axis=1)\n",
    "raw_test_data2 = temp.drop(columns = \"Status\").rename(columns = {\"Superheated\": \"Superheated_status\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data2[[\"Liquid Critical Pressure (bar)\", \"Liquid Boiling Temperature (K)\", \"Liquid Critical Temperature (K)\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(raw_data3['Liquid Critical Pressure (bar)'], drop_first=False)\n",
    "dummies.columns = ['37.9', '42.5']\n",
    "dummy_col = dummies['42.5'].rename(f\"Liquid Critical Pressure (bar)\") * 1\n",
    "raw_data3 = pd.concat([raw_data3.drop('Liquid Critical Pressure (bar)', axis=1), dummy_col], axis=1)\n",
    "\n",
    "dummies = pd.get_dummies(raw_data3['Liquid Boiling Temperature (K)'], drop_first=False)\n",
    "dummies.columns = ['-42', '-1']\n",
    "dummy_col = dummies['-42'].rename(f\"Liquid Boiling Temperature (K)\") * 1\n",
    "raw_data3 = pd.concat([raw_data3.drop('Liquid Boiling Temperature (K)', axis=1), dummy_col], axis=1)\n",
    "\n",
    "dummies = pd.get_dummies(raw_data3['Liquid Critical Temperature (K)'], drop_first=False)\n",
    "dummies.columns = ['152.0', '96.7']\n",
    "dummy_col = dummies['152.0'].rename(f\"Liquid Critical Temperature (K)\") * 1\n",
    "raw_data3 = pd.concat([raw_data3.drop('Liquid Critical Temperature (K)', axis=1), dummy_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(raw_test_data2['Liquid Critical Pressure (bar)'], drop_first=False)\n",
    "dummies.columns = ['37.9', '42.5']\n",
    "dummy_col = dummies['42.5'].rename(f\"Liquid Critical Pressure (bar)\") * 1\n",
    "raw_test_data2 = pd.concat([raw_test_data2.drop('Liquid Critical Pressure (bar)', axis=1), dummy_col], axis=1)\n",
    "\n",
    "dummies = pd.get_dummies(raw_test_data2['Liquid Boiling Temperature (K)'], drop_first=False)\n",
    "dummies.columns = ['-42', '-1']\n",
    "dummy_col = dummies['-42'].rename(f\"Liquid Boiling Temperature (K)\") * 1\n",
    "raw_test_data2 = pd.concat([raw_test_data2.drop('Liquid Boiling Temperature (K)', axis=1), dummy_col], axis=1)\n",
    "\n",
    "dummies = pd.get_dummies(raw_test_data2['Liquid Critical Temperature (K)'], drop_first=False)\n",
    "dummies.columns = ['152.0', '96.7']\n",
    "dummy_col = dummies['152.0'].rename(f\"Liquid Critical Temperature (K)\") * 1\n",
    "raw_test_data2 = pd.concat([raw_test_data2.drop('Liquid Critical Temperature (K)', axis=1), dummy_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a lookup for the properties of each substance (there are only 2 distinct substance present; we will denote them 0 and 1). This table will allow us to view their properties later\n",
    "substance_properties = raw_data2[[\"Liquid Critical Pressure (bar)\", \"Liquid Boiling Temperature (K)\", \"Liquid Critical Temperature (K)\"]].drop_duplicates()\n",
    "substance_properties = substance_properties.rename(index = {substance_properties.index[1]: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative and 0 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = 2\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*2.5, n_rows*2))\n",
    "\n",
    "i = 0\n",
    "for var in raw_data3.columns:\n",
    "    temp = raw_data3[raw_data3[var] < 0]\n",
    "    \n",
    "    if not temp.empty:\n",
    "        ax = axs[i//n_cols, i%n_cols]\n",
    "        temp[var].hist(bins=15, ax = ax)\n",
    "        ax.set_title(f'{var}')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data3[\"Liquid Boiling Temperature (K)\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the \"BLEVE Height (m)\" is \"the distance of the tank to the ground (in meter)\" [sic]. After confirming with the source of the data that this can not be negative, we must remove it from our data.\n",
    "\n",
    "Additionally, the \"Liquid Boiling Temperature\" is in Kelvin, however, all values in our set are negative (which is impossible as Kelvin is an absolute scale). Whilst this appears to be invalid, we'll discuss in 2.6.6 how this is actually just a mistake in the recording of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data3 = raw_data3.query(\"`BLEVE Height (m)` > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Removing Duplicates\n",
    "display(raw_data3[raw_data3.duplicated(keep=False)].sort_values(by=raw_data3.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data4 = raw_data3.drop_duplicates()\n",
    "print(f\"Data dropped: {len(raw_data3) - len(raw_data4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into train, validation and test sets before analysing the data (so we can test our hypotheses locally before submitting them for assessment). However, before we do this, we'll do perform any changes that apply to all datasets here (so we don't have to add them to each dataset separately). This mainly includes renaming the columns to something more friendly for analysis (i.e. snake_case), as well as adding features that we'll explore later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_cols = [\n",
    "    \"ID\",\n",
    "    \"failure_pressure\",\n",
    "    \"liquid_pct\",\n",
    "    \"tank_w\",\n",
    "    \"tank_l\",\n",
    "    \"tank_h\",\n",
    "    \"BLEVE_h\",\n",
    "    \"vapour_height\",\n",
    "    \"vapour_temp\",\n",
    "    \"liquid_temp\",\n",
    "    \"obstacle_dist\",\n",
    "    \"obstacle_w\",\n",
    "    \"obstacle_h\",\n",
    "    \"obstacle_thk\",\n",
    "    \"obstacle_angle\",\n",
    "    \"sensor_id\",\n",
    "    \"sensor_side\",\n",
    "    \"sensor_x\",\n",
    "    \"sensor_y\",\n",
    "    \"sensor_z\",\n",
    "    \"tgt_pressure\",\n",
    "    \"superheated_status\",\n",
    "    \"lqd_crit_pressure\",\n",
    "    \"lqd_boil_temp\",\n",
    "    \"lqd_crit_temp\",\n",
    "    \"event_num\",\n",
    "    \"tank_volume\",\n",
    "    \"net_sensor_dist\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_names = dict(zip(raw_data4.columns, renamed_cols))\n",
    "\n",
    "raw_data4 = raw_data4.rename(columns = dict_names)\n",
    "raw_test_data2.rename(columns = dict_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we can see that many of our variables relate to each other\n",
    "* E.g. we have tank height, length and width, which suggest that we should create a variable for the tank volume.\n",
    "* Also, we have the location of sensors. This is quite important, but we can group sensors by \"front\", \"back\" and \"side\" (rather than looking at them individually)\n",
    "* Furthermore, we can try convert the sensor's position into a distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data5 = raw_data4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tank_axis = [\"tank_w\", \"tank_h\", \"tank_l\"]\n",
    "raw_data5[\"tank_volume\"] = raw_data5[tank_axis].prod(axis = 1)\n",
    "raw_data5.drop(columns = tank_axis, inplace = True)\n",
    "\n",
    "raw_data5[\"sensor_location\"] = raw_data5[\"sensor_side\"].map({1: 1, 2: 2, 3: 3, 4: 3, 5: 3}) # changes 4 and 5 (both sides) to 3 (1 = back, 2 = front, 3 = sides)\n",
    "\n",
    "sensor_vars = [\"sensor_x\", \"sensor_y\", \"net_z\"]\n",
    "raw_data5[\"net_z\"] = raw_data5[\"sensor_z\"] - raw_data5[\"BLEVE_h\"]\n",
    "raw_data5[\"net_sensor_dist\"] = np.linalg.norm(raw_data5[sensor_vars], axis=1)\n",
    "sensor_vars.append(\"sensor_z\")\n",
    "raw_data5.drop(columns = sensor_vars, inplace = True)\n",
    "\n",
    "lqd_properties = [\"lqd_crit_pressure\", \"lqd_boil_temp\", \"lqd_crit_temp\"]\n",
    "raw_data5[\"substance\"] = raw_data5[lqd_properties].prod(axis = 1)\n",
    "raw_data5.drop(columns = lqd_properties, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_data2[\"tank_volume\"] = raw_test_data2[tank_axis].prod(axis = 1)\n",
    "raw_test_data2[\"sensor_location\"] = raw_test_data2[\"sensor_side\"].map({1: 1, 2: 2, 3: 3, 4: 3, 5: 3})\n",
    "raw_test_data2[\"net_z\"] = raw_test_data2[\"sensor_z\"] - raw_test_data2[\"BLEVE_h\"]\n",
    "raw_test_data2[\"net_sensor_dist\"] = np.linalg.norm(raw_test_data2[sensor_vars], axis=1)\n",
    "raw_test_data2[\"substance\"] = raw_test_data2[lqd_properties].prod(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we'll add an \"event_num\" so we can tell when data from different sensors has come from the same event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_num = 1\n",
    "prev_id = raw_data5.loc[0, \"sensor_id\"]\n",
    "\n",
    "event_nums = []\n",
    "\n",
    "for index, row in raw_data5.iterrows():\n",
    "    curr_id = row[\"sensor_id\"]\n",
    "    if curr_id < prev_id:\n",
    "        event_num += 1 \n",
    "    \n",
    "    event_nums.append(event_num)\n",
    "    prev_id = curr_id\n",
    "\n",
    "raw_data5.loc[:,\"event_num\"] = event_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "val_train_ratio = 0.7\n",
    "val_val_ratio = 0.15\n",
    "\n",
    "n_events = max(raw_data5[\"event_num\"])\n",
    "val_train_qty = int(val_train_ratio * n_events)\n",
    "val_val_qty = int(val_val_ratio * n_events) + val_train_qty\n",
    "\n",
    "train_split = raw_data5[raw_data5[\"event_num\"]<val_train_qty]\n",
    "validation_split = raw_data5[(raw_data5[\"event_num\"]>=val_train_qty) & (raw_data5[\"event_num\"]<val_val_qty)]\n",
    "test_split = raw_data5[raw_data5[\"event_num\"]>=val_val_qty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data = train_split.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Immediately based off priors, we can see that many of our variables relate to each other. E.g. we have tank height, length and width, which suggest that we should create a variable for the tank volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Variables vs tgt_pressure\n",
    "def plot_tgt_var(df, vars = None, n_cols = 4):\n",
    "    if vars == None:\n",
    "        vars = df.columns\n",
    "        \n",
    "    numeric_cols = df[vars].select_dtypes(include = np.number).columns.to_list()\n",
    "    n_cols = n_cols\n",
    "    n_rows = int(len(numeric_cols) / n_cols) + (len(numeric_cols) % n_cols > 0)\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2.5, n_rows * 2))\n",
    "    \n",
    "    i = 0\n",
    "    for col_name in numeric_cols:\n",
    "        if col_name != \"tgt_pressure\":\n",
    "            ax = axs[i//n_cols, i%n_cols]\n",
    "            ax.scatter(df[col_name], df[\"tgt_pressure\"])\n",
    "            ax.set_title(f\"{col_name}\")\n",
    "            i += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tgt_var(ft_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data.corr().style.background_gradient(cmap = \"coolwarm\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data.corr()[[\"tgt_pressure\"]].T.style.background_gradient(cmap = \"coolwarm\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ft_data.loc[10:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_tgt_var(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into distinguishing by sensor_side (instead of individual sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data2[[\"Sensor Position Side\", \"Sensor ID\"]].drop_duplicates().sort_values(by = \"Sensor ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can group IDs by Position Side as such:\n",
    "# 1: 1-9\n",
    "# 2: 10-18\n",
    "# 3: 19-21\n",
    "# 4: 22-24\n",
    "# 5: 25-27\n",
    "\n",
    "# This was done above in 2.5.1 \"sensor_location\" (using 1 = back, 2 = front, 3 = sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpd_sensor_loc = ft_data.groupby(\"sensor_location\")\n",
    "grpd_sensor_loc_vld = validation_split.groupby(\"sensor_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Sensor Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Variables vs tgt_pressure for Each Sensor\n",
    "def plot_sensor_data(grpd_data, vars = None, n_cols = 4):\n",
    "    if vars == None:\n",
    "        vars = df.columns\n",
    "        \n",
    "    n_cols = min(len(vars), n_cols)\n",
    "    n_rows = 27\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2.5, n_rows * 2))\n",
    "    \n",
    "    i = 0\n",
    "    for sensor_id, df in grpd_data:\n",
    "        for col_name in vars:\n",
    "            ax = axs[i//n_cols, i%n_cols]\n",
    "            ax.scatter(df[col_name], df[\"tgt_pressure\"])\n",
    "            ax.set_title(f\"{i//n_cols+1}: {col_name}\")\n",
    "            i += 1\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grpd = ft_data.groupby(\"sensor_id\")\n",
    "\n",
    "# plot_sensor_data(grpd, [\"sensor_x\", \"sensor_y\", \"sensor_z\", \"net_sensor_dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = 9\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2.5, n_rows * 2))\n",
    "\n",
    "i = 0\n",
    "for sensor_id, df in grpd:\n",
    "    ax = axs[i//n_cols, i%n_cols]\n",
    "    ax.scatter(df[\"obstacle_dist\"], df[\"net_sensor_dist\"])\n",
    "    ax.set_title(f\"{i+1}: sens_dist vs obs_dist\")\n",
    "    i += 1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_intercepts = []\n",
    "\n",
    "for sensor_id, df in grpd:\n",
    "    X = df[[\"obstacle_dist\"]]\n",
    "    y = df[\"net_sensor_dist\"]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Get y-intercept\n",
    "    y_intercept = model.intercept_\n",
    "    y_intercepts.append(y_intercept)\n",
    "\n",
    "# Plot y-intercepts on a bar graph\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(range(1, len(y_intercepts) + 1), y_intercepts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data.corr()[[\"tgt_pressure\",\"net_sensor_dist\",\"obstacle_dist\"]].T.style.background_gradient(cmap = \"coolwarm\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_stats(df, vars):\n",
    "    r_sq_result = {}\n",
    "    \n",
    "    for predictor in vars:\n",
    "        X = df[[predictor]]\n",
    "        y = df[\"tgt_pressure\"]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "        r_squared = r2_score(y, y_pred)\n",
    "        coefficients = model.coef_  # Get the coefficients\n",
    "        r_sq_result[predictor] = {\"R-squared\": r_squared, \"Coefficients\": coefficients}\n",
    "    \n",
    "    \n",
    "    for key, val in r_sq_result.items():\n",
    "        print(f\"### {key} ###\\nCoeff = {val['Coefficients'][0]:.4f}\\nR^2 = {val['R-squared']:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ft_data[[\"net_sensor_dist\"]]\n",
    "y = ft_data[\"tgt_pressure\"]\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "r_squared = r2_score(y, y_pred)\n",
    "coefficients = model.coef_  # Get the coefficients\n",
    "display(pd.DataFrame({\"R-squared\": r_squared, \"Coefficients\": coefficients}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stats(ft_data, [\"net_sensor_dist\", \"obstacle_dist\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: it appears that the net_sensor_dist and obstacle_distance_to_BLEVE are very similar in nature, and without more information regarding the nature of the experiment, it is hard to pinpoint where exactly this difference comes from.net_sensor_dist has a stronger correlation with tgt_pressure than the obstacle_distance, we will use that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_calc(y_tgt, y_pred):\n",
    "        return np.mean(np.abs(1 - y_pred / y_tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def out_of_sample_test(model, data):\n",
    "    y2 = data[\"tgt_pressure\"]\n",
    "    X2 = data.drop(columns=[\"tgt_pressure\"])\n",
    "    y2_pred = model.predict(X2)\n",
    "    \n",
    "    r2_2 = r2_score(y2, y2_pred)\n",
    "    mape2 = mape_calc(y2, y2_pred)\n",
    "    \n",
    "    print(f\"R^2: {r2_2:.4f}, MAPE: {mape2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selected_r2(data, response, max_features=5, select_features = 5, criterion='aic', k = False):\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = float('inf'), float('inf')\n",
    "    if k == False:\n",
    "        k = '-1 +'\n",
    "    else:\n",
    "        k = ''\n",
    "    while remaining and len(selected) < max_features:\n",
    "        scores_with_candidates = []\n",
    "        if not selected:\n",
    "            curr_score = float(\"inf\")\n",
    "            curr_r2 = 0\n",
    "        else:\n",
    "            curr_formula = f\"{response} ~ {k}{' + '.join(selected)}\"\n",
    "            curr_model = sm.OLS.from_formula(curr_formula, data).fit()\n",
    "            curr_r2 = curr_model.rsquared\n",
    "            if criterion == \"aic\":\n",
    "                curr_score = curr_model.aic\n",
    "            elif criterion == \"bic\":\n",
    "                curr_score = curr_model.bic\n",
    "        for candidate in remaining:\n",
    "            formula = f\"{response} ~ {k}{' + '.join(selected + [candidate])}\"\n",
    "            if criterion == 'aic':\n",
    "                model = sm.OLS.from_formula(formula, data).fit()\n",
    "                score = model.aic\n",
    "                r_squared = model.rsquared\n",
    "            elif criterion == 'bic':\n",
    "                model = sm.OLS.from_formula(formula, data).fit()\n",
    "                score = model.bic\n",
    "                r_squared = model.rsquared\n",
    "            else:\n",
    "                raise ValueError(\"Invalid: use 'aic' or 'bic'\")\n",
    "            scores_with_candidates.append((score, r_squared, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        \n",
    "        print(f\"\\nBest variables (current: {criterion.upper()} = {curr_score:.2f}, R^2 = {curr_r2:.4f}):\")\n",
    "        for i, (score, r_squared, candidate) in enumerate(scores_with_candidates[:select_features], 1): # enumerate from 1 instead of 0\n",
    "            print(f\"{i}. {candidate.ljust(20)} \\tAIC={score:.2f}, \\tR^2={r_squared:.4f}\")\n",
    "        \n",
    "        user_input = input(f\"Variable to add (1-{select_features}): \")\n",
    "        try:\n",
    "            choice = int(user_input)\n",
    "            if 1 <= choice <= select_features:\n",
    "                best_candidate = scores_with_candidates[choice - 1][2]\n",
    "                print(f\"\\n### Adding {best_candidate} ###\")\n",
    "                remaining.remove(best_candidate)\n",
    "                selected.append(best_candidate)\n",
    "                current_score = scores_with_candidates[choice - 1][0]\n",
    "            else:\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(\"Invalid. Enter a number\")\n",
    "\n",
    "    if not selected:\n",
    "        raise ValueError(\"No variables added to model\")\n",
    "            \n",
    "    formula = f\"{response} ~ {k}{' + '.join(selected)}\"\n",
    "    model = sm.OLS.from_formula(formula, data).fit()\n",
    "\n",
    "    y_tgt = data[response]\n",
    "    y_pred = model.predict(data).clip(0)\n",
    "    mape = mape_calc(y_tgt, y_pred)\n",
    "    \n",
    "    print(f\"\\n\\n### METRICS ###\\nMape:\\t{mape:.4f} \\nR^2:\\t{model.rsquared:.4f}\")\n",
    "    print(\"\\n\",model.summary(),\"\\n\")\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.scatter(y_pred, y_tgt)\n",
    "    plt.plot([y_pred.min(), y_pred.max()], [y_pred.min(), y_pred.max()], color='red', linestyle='--', label='y = x')\n",
    "    \n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Accuracy of Predictions\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selected_mape(data, response, max_features=5, select_features=5, criterion='aic', k=False):\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = float('inf'), float('inf')\n",
    "    if k == False:\n",
    "        k = '-1 +'\n",
    "    else:\n",
    "        k = ''\n",
    "    while remaining and len(selected) < max_features:\n",
    "        scores_with_candidates = []\n",
    "        if not selected:\n",
    "            curr_score = float(\"inf\")\n",
    "            curr_mape = float(\"inf\")\n",
    "            curr_r2 = 0\n",
    "        else:\n",
    "            curr_formula = f\"{response} ~ {k}{' + '.join(selected)}\"\n",
    "            curr_model = sm.OLS.from_formula(curr_formula, data).fit()\n",
    "            curr_mape = mape_calc(data[response], curr_model.predict(data))\n",
    "            curr_r2 = curr_model.rsquared\n",
    "            if criterion == \"aic\":\n",
    "                curr_score = curr_model.aic\n",
    "            elif criterion == \"bic\":\n",
    "                curr_score = curr_model.bic\n",
    "        for candidate in remaining:\n",
    "            formula = f\"{response} ~ {k}{' + '.join(selected + [candidate])}\"\n",
    "            if criterion == 'aic':\n",
    "                model = sm.OLS.from_formula(formula, data).fit()\n",
    "                score = model.aic\n",
    "            elif criterion == 'bic':\n",
    "                model = sm.OLS.from_formula(formula, data).fit()\n",
    "                score = model.bic\n",
    "            else:\n",
    "                raise ValueError(\"Invalid: use 'aic' or 'bic'\")\n",
    "            mape = mape_calc(data[response], model.predict(data))\n",
    "            r2 = model.rsquared\n",
    "            scores_with_candidates.append((score, mape, r2, candidate))\n",
    "        scores_with_candidates.sort(key=lambda x: x[1])\n",
    "        \n",
    "        print(f\"\\nBest variables (current: {criterion.upper()} = {curr_score:.2f}, MAPE = {curr_mape:.4f}, R^2 = {curr_r2:.4f}):\")\n",
    "        for i, (score, mape, r2, candidate) in enumerate(scores_with_candidates[:select_features], 1):\n",
    "            print(f\"{i}. {candidate.ljust(20)} \\tAIC={score:.2f}, \\tMAPE={mape:.4f}, \\tR^2={r2:.4f}\")\n",
    "\n",
    "        user_input = input(f\"Variable to add (1-{select_features}): \")\n",
    "        try:\n",
    "            choice = int(user_input)\n",
    "            if 1 <= choice <= select_features:\n",
    "                best_candidate = scores_with_candidates[choice - 1][3]\n",
    "                print(f\"\\n### Adding {best_candidate} ###\")\n",
    "                remaining.remove(best_candidate)\n",
    "                selected.append(best_candidate)\n",
    "                current_score = scores_with_candidates[choice - 1][0]\n",
    "            else:\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(\"Invalid. Enter a number\")\n",
    "\n",
    "    if not selected:\n",
    "        raise ValueError(\"No variables added to model\")\n",
    "\n",
    "    formula = f\"{response} ~ {k}{' + '.join(selected)}\"\n",
    "    model = sm.OLS.from_formula(formula, data).fit()\n",
    "\n",
    "    y_tgt = data[response]\n",
    "    y_pred = model.predict(data).clip(0)\n",
    "    mape = mape_calc(y_tgt, y_pred)\n",
    "\n",
    "    print(f\"\\n\\n### METRICS ###\\nMAPE:\\t{mape:.4f} \\n{criterion.upper()}:\\t{current_score:.2f}\")\n",
    "    print(\"\\n\",model.summary(),\"\\n\")\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.scatter(y_pred, y_tgt)\n",
    "    plt.plot([y_pred.min(), y_pred.max()], [y_pred.min(), y_pred.max()], color='red', linestyle='--', label='y = x')\n",
    "\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Accuracy of Predictions\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_model = forward_selected_r2(ft_data, \"tgt_pressure\", criterion='aic', k = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sample_test(selected_model, validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = selected_model.predict(raw_test_data2).clip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'ID': preds.index, 'Target Pressure (bar)': preds.values})\n",
    "output_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing by Sensor Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpd_sensor_side = ft_data.groupby(\"sensor_side\")\n",
    "grpd_sensor_side_vld = validation_split.groupby(\"sensor_side\")\n",
    "grpd_sensor_side_test = raw_test_data2.groupby(\"sensor_side\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "side_dict = {1: \"back\", 2: \"front\", 3: \"side_L\", 4: \"side_T\", 5: \"side_R\"}\n",
    "\n",
    "for side, df in grpd_sensor_side:\n",
    "    print(f\"\\n##### SIDE: {side_dict[side]} #####\\n\")\n",
    "    model_side = f\"model_{side_dict[side]}\" \n",
    "    model = forward_selected_mape(df, \"tgt_pressure\", criterion='aic', k=False)\n",
    "    models[model_side] = model\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (side, df) in zip(models.values(), grpd_sensor_side_vld):\n",
    "    out_of_sample_test(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (side, df) in zip(models.values(), grpd_sensor_side_test):\n",
    "    model.predict(df).clip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [model.predict(df).clip(0) for model, (_, df) in zip(models.values(), grpd_sensor_side_test)]\n",
    "preds_concat = pd.concat(preds).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'ID': preds_concat.index, 'Target Pressure (bar)': preds_concat.values})\n",
    "output_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing by Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpd_sensor = ft_data.groupby(\"sensor_id\")\n",
    "grpd_sensor_vld = validation_split.groupby(\"sensor_id\")\n",
    "grpd_sensor_tst = test_split.groupby(\"sensor_id\")\n",
    "grpd_sensor_test = raw_test_data2.groupby(\"sensor_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for side, df in grpd_sensor:\n",
    "    if side % 4 == 0:\n",
    "        print(f\"\\n##### SIDE: {side} #####\\n\")\n",
    "        model_side = f\"model_{side}\" \n",
    "        model = forward_selected_mape(df, \"tgt_pressure\", criterion='aic', k=False)\n",
    "        models[model_side] = model\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor10 = ft_data.query(\"sensor_id == 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sensor10.sort_values(\"tgt_pressure\", ascending = False).round(2).drop(columns = [\"ID\", \"event_num\", \"BLEVE_h\", \"obstacle_angle\", \"sensor_side\", \"sensor_id\", \"sensor_location\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(temp.columns):\n",
    "    ax = axes[i]\n",
    "    ax.plot(temp.index, temp[column], alpha = 0.2)\n",
    "    ewma = temp[column].ewm(span=10).mean()\n",
    "    ax.plot(temp.index, ewma, label='EWMA', color='orange')\n",
    "    ax.set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "m1 = [\"tank_volume\", \"vapour_height\", \"net_sensor_dist\", \"failure_pressure\"]\n",
    "m2 = [\"tank_volume\", \"vapour_height\"]\n",
    "m3 = [\"tank_volume\", \"vapour_height\"]\n",
    "\n",
    "for side, df in grpd_sensor:\n",
    "    if side <= 9:\n",
    "        model_side = f\"model_{int(side)}\" \n",
    "        temp_formula = f\"tgt_pressure ~ {' + '.join(m1)} - 1\"\n",
    "        temp_model = sm.OLS.from_formula(temp_formula, df).fit()\n",
    "        temp_mape = mape_calc(df[\"tgt_pressure\"], temp_model.predict(df))\n",
    "        temp_r2 = temp_model.rsquared\n",
    "    \n",
    "        models[model_side] = temp_model\n",
    "        \n",
    "    elif side <= 15:\n",
    "        model_side = f\"model_{int(side)}\" \n",
    "        temp_formula = f\"tgt_pressure ~ {' + '.join(m2)} - 1\"\n",
    "        temp_model = sm.OLS.from_formula(temp_formula, df).fit()\n",
    "        temp_mape = mape_calc(df[\"tgt_pressure\"], temp_model.predict(df))\n",
    "        temp_r2 = temp_model.rsquared\n",
    "    \n",
    "        models[model_side] = temp_model\n",
    "\n",
    "    else:\n",
    "        model_side = f\"model_{int(side)}\" \n",
    "    \n",
    "        temp_formula = f\"tgt_pressure ~ {' + '.join(m3)} - 1\"\n",
    "        temp_model = sm.OLS.from_formula(temp_formula, df).fit()\n",
    "        temp_mape = mape_calc(df[\"tgt_pressure\"], temp_model.predict(df))\n",
    "        temp_r2 = temp_model.rsquared\n",
    "    \n",
    "        models[model_side] = temp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (side, df) in zip(models.values(), grpd_sensor_vld):\n",
    "    if side in [10,16]:\n",
    "        print(\"\\n\")\n",
    "    out_of_sample_test(model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (side, df) in zip(models.values(), grpd_sensor_test):\n",
    "    model.predict(df).clip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [model.predict(df).clip(0) for model, (_, df) in zip(models.values(), grpd_sensor_test)]\n",
    "preds_concat = pd.concat(preds).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'ID': preds_concat.index, 'Target Pressure (bar)': preds_concat.values})\n",
    "output_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_df = pd.DataFrame()\n",
    "\n",
    "for i, model in enumerate(models.values()):\n",
    "    coefficients = model.params\n",
    "    coefficients_df[f'{i+1}'] = coefficients\n",
    "\n",
    "coefficients_df = coefficients_df.T\n",
    "coefficients_df.index = coefficients_df.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_range = coefficients_df[coefficients_df.index < 9]\n",
    "second_range = coefficients_df[(coefficients_df.index >= 9) & (coefficients_df.index <= 15)]\n",
    "third_range = coefficients_df[coefficients_df.index > 15]\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "for column in first_range.columns:\n",
    "    plt.plot(first_range.index, first_range[column], label=column)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "for column in second_range.columns:\n",
    "    plt.plot(second_range.index, second_range[column], label=column)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "for column in third_range.columns:\n",
    "    plt.plot(third_range.index, third_range[column], label=column)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data2 = ft_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the properties of the 2 unique substances present in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substance_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in 2.3.2 (and by using common sense), a sub-0 boiling temperature raises some red flags. Through some elementary research, we can discover that these are the distinct properties of 2 unique molecules; n-butane and propane respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_new_BP(p2, element):\n",
    "    if element == \"n-butane\" or element == 0:\n",
    "        h = 22.40 * 1000\n",
    "        p1 = 1\n",
    "        t1 = -1 + 273.15\n",
    "    elif element == \"propane\" or element == 1:\n",
    "        h = 16.25 * 1000\n",
    "        p1 = 1\n",
    "        t1 = -42 + 273.15\n",
    "    else:\n",
    "        raise ValueError(\"Element must be propane or n-butane\")\n",
    "\n",
    "    calc = 1/t1 - 8.3145 * np.log(p2/p1)/h\n",
    "    return round(1/calc, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_dict = {0: -1.0, 1: -42.0}\n",
    "ft_data2[\"BP_orig\"] = ft_data2[\"substance\"].map(map_dict)\n",
    "ft_data2[\"BP_new\"] = ft_data2.apply(lambda row: calc_new_BP(row[\"failure_pressure\"], row[\"substance\"]), axis = 1)\n",
    "ft_data2[\"temp_excess\"] =  ft_data2[\"liquid_temp\"] - ft_data2[\"BP_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor1 = list(ft_data2.groupby(\"sensor_id\"))[14][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tgt_var(sensor1.query(\"substance == 0\"),[\"vapour_temp\", \"liquid_temp\",\"failure_pressure\", \"temp_excess\"], n_cols = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_tgt_var(sensor1.query(\"substance == 1\"),[\"vapour_temp\", \"liquid_temp\",\"failure_pressure\", \"temp_excess\"], n_cols = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNfG3FBYs+RR4dcNrZ4B0J3",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
